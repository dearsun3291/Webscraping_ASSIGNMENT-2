{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *WEBSCRAPING ASSIGNMENT -2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all required dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import selenium as sn\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,  experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to input search designation & scrape data\n",
    "def q_1(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\") # Calling webdriver\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    search_modify = driver.find_element_by_xpath(\"//span[@class = 'quick-search-bar__view__modify-link']\")\n",
    "    search_modify.click()\n",
    "    design = input('Enter the job_title you are look for:')\n",
    "    search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    search_job.send_keys(design)\n",
    "    search_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "    search_location.clear()\n",
    "    search_location.send_keys('Bangalore')\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'btn-primary']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #scraping required data & making a list of these\n",
    "    post_name = []\n",
    "    company_name=[]\n",
    "    experience_required=[]\n",
    "    p_name = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    job_loc = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "    com_name = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    exp = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "    for i in p_name[0:10]:\n",
    "        post_name.append(i.text)\n",
    "\n",
    "    for i in com_name[0:10]:\n",
    "        company_name.append(i.text)\n",
    "    \n",
    "    for i in job_loc[0:30]:\n",
    "        experience_required.append(i.text)\n",
    "        \n",
    "    driver.close()  \n",
    "    df = pd.DataFrame({})# creating data frame\n",
    "    df['job_title'] = post_name[0:10]\n",
    "    df['job_location'] = experience_required[2::3][0:10]\n",
    "    df['company_name']= company_name[0:10]\n",
    "    df['experience_required'] = experience_required[0::3][0:10]\n",
    "    df.to_csv('A_2_Q1.csv') # exporting data frame as csv file\n",
    "    return(df) # returing the created data frame from the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job_title you are look for:Data Analyst\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azure Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RedLock, Inc</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_title                    job_location  \\\n",
       "0  Azure Data Analyst             Bangalore/Bengaluru   \n",
       "1        Data Analyst             Bangalore/Bengaluru   \n",
       "2        Data Analyst  Bangalore/Bengaluru(Devalapur)   \n",
       "3        Data Analyst             Bangalore/Bengaluru   \n",
       "4        Data Analyst             Bangalore/Bengaluru   \n",
       "5        Data Analyst             Bangalore/Bengaluru   \n",
       "6        Data Analyst             Bangalore/Bengaluru   \n",
       "7        Data Analyst             Bangalore/Bengaluru   \n",
       "8        Data Analyst             Bangalore/Bengaluru   \n",
       "9        Data Analyst             Bangalore/Bengaluru   \n",
       "\n",
       "                                  company_name experience_required  \n",
       "0  Capgemini Technology Services India Limited             6-8 Yrs  \n",
       "1                                 RedLock, Inc             0-0 Yrs  \n",
       "2                        Super India Tech Mark             0-2 Yrs  \n",
       "3                            tech mahindra ltd             4-8 Yrs  \n",
       "4         CONDUENT BUSINESS SERVICES INDIA LLP             1-2 Yrs  \n",
       "5      GlaxoSmithKline Pharmaceuticals Limited             2-7 Yrs  \n",
       "6                     Myntra Designs Pvt. Ltd.             3-6 Yrs  \n",
       "7                     Myntra Designs Pvt. Ltd.             4-8 Yrs  \n",
       "8                     Myntra Designs Pvt. Ltd.             3-8 Yrs  \n",
       "9                     Myntra Designs Pvt. Ltd.             4-8 Yrs  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the function to scrape data for Data Analyst\n",
    "q_1('https://www.naukri.com/jobs-in-india')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job_title you are look for:Data Scientist\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GAMMA Lead Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                  Data Scientist - Machine Learning   \n",
       "3     Data Scientist || Data Analyst || Data science   \n",
       "4                        Data Scientist - IBM Garage   \n",
       "5                          GAMMA Lead Data Scientist   \n",
       "6             DBCG IND - GAMMA Senior Data Scientist   \n",
       "7               Data Scientist/Senior Data Scientist   \n",
       "8  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9                      Global Medical Data Scientist   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "4  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "6    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "7  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "8  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 company_name experience_required  \n",
       "0       CronJ IT Technologies Private Limited             0-1 Yrs  \n",
       "1                      Corner Stone Solutions             0-1 Yrs  \n",
       "2                                 AugmatrixGo             2-5 Yrs  \n",
       "3  Inspiration Manpower Consultancy Pvt. Ltd.            6-11 Yrs  \n",
       "4                      IBM India Pvt. Limited             5-8 Yrs  \n",
       "5                     Boston Consulting Group            7-12 Yrs  \n",
       "6                     Boston Consulting Group            6-10 Yrs  \n",
       "7    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED             4-8 Yrs  \n",
       "8                                    CES Ltd.             2-7 Yrs  \n",
       "9     GlaxoSmithKline Pharmaceuticals Limited            5-10 Yrs  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the above function to scrape data for Data Scientist post\n",
    "q_1('https://www.naukri.com/jobs-in-india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GAMMA Lead Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                  Data Scientist - Machine Learning   \n",
       "3     Data Scientist || Data Analyst || Data science   \n",
       "4                        Data Scientist - IBM Garage   \n",
       "5                          GAMMA Lead Data Scientist   \n",
       "6             DBCG IND - GAMMA Senior Data Scientist   \n",
       "7               Data Scientist/Senior Data Scientist   \n",
       "8  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9                      Global Medical Data Scientist   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "4  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "6    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "7  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "8  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 company_name experience_required  \n",
       "0       CronJ IT Technologies Private Limited             0-1 Yrs  \n",
       "1                      Corner Stone Solutions             0-1 Yrs  \n",
       "2                                 AugmatrixGo             2-5 Yrs  \n",
       "3  Inspiration Manpower Consultancy Pvt. Ltd.            6-11 Yrs  \n",
       "4                      IBM India Pvt. Limited             5-8 Yrs  \n",
       "5                     Boston Consulting Group            7-12 Yrs  \n",
       "6                     Boston Consulting Group            6-10 Yrs  \n",
       "7    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED             4-8 Yrs  \n",
       "8                                    CES Ltd.             2-7 Yrs  \n",
       "9     GlaxoSmithKline Pharmaceuticals Limited            5-10 Yrs  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping data for Data scientist post using different function\n",
    "def q_2(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\") # Calling webdriver\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    search_modify = driver.find_element_by_xpath(\"//span[@class = 'quick-search-bar__view__modify-link']\")\n",
    "    search_modify.click()\n",
    "    search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    search_job.send_keys('Data Scientist')\n",
    "    search_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "    search_location.clear()\n",
    "    search_location.send_keys('Bangalore')\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'btn-primary']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scraping required data and making list of each required feature\n",
    "    post_name = []\n",
    "    company_name=[]\n",
    "    experience_required=[]\n",
    "    p_name = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    job_loc = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "    com_name = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    exp = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "    for i in p_name[0:10]:\n",
    "        post_name.append(i.text)\n",
    "\n",
    "    for i in com_name[0:10]:\n",
    "        company_name.append(i.text)\n",
    "    \n",
    "    for i in job_loc[0:30]:\n",
    "        experience_required.append(i.text)\n",
    "        \n",
    "    driver.close()  \n",
    "    df = pd.DataFrame({})# creating data frame\n",
    "    df['job_title'] = post_name[0:10]\n",
    "    df['job_location'] = experience_required[2::3][0:10]\n",
    "    df['company_name']= company_name[0:10]\n",
    "    df['experience_required'] = experience_required[0::3][0:10]\n",
    "    df.to_csv('A_2_Q2.csv') # exporting data frame as csv file\n",
    "    return(df) # returing the created data frame from the function\n",
    "    \n",
    "# calling function to scrape data   \n",
    "q_2('https://www.naukri.com/jobs-in-india')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Females Required- Data Scientist- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Required- Data Scientist (NLP)-Axis Bank - 6 m...</td>\n",
       "      <td>Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...</td>\n",
       "      <td>Axis Bank Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning (IS...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                        Data Scientist - IBM Garage   \n",
       "1  Data Scientist/Data Analyst - Python/Machine L...   \n",
       "2            Females Required- Data Scientist- Noida   \n",
       "3         Data Scientist - Python & Machine Learning   \n",
       "4         Data Scientist - Python & Machine Learning   \n",
       "5  Data Scientist - Python / Machine Learning / T...   \n",
       "6         Data Scientist - Python & Machine Learning   \n",
       "7  Required- Data Scientist (NLP)-Axis Bank - 6 m...   \n",
       "8  Data Scientist - Python / Machine Learning / T...   \n",
       "9  Data Scientist - Python & Machine Learning (IS...   \n",
       "\n",
       "                                        job_location            company_name  \\\n",
       "0  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  IBM India Pvt. Limited   \n",
       "1                                  Mumbai, Ghaziabad          Change leaders   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR                Randstad   \n",
       "3  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...     FUTURES AND CAREERS   \n",
       "4  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...     FUTURES AND CAREERS   \n",
       "5  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...     FUTURES AND CAREERS   \n",
       "6  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...     FUTURES AND CAREERS   \n",
       "7  Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...       Axis Bank Limited   \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...     FUTURES AND CAREERS   \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...     FUTURES AND CAREERS   \n",
       "\n",
       "  experience_required  \n",
       "0             5-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             3-7 Yrs  \n",
       "3             2-7 Yrs  \n",
       "4             2-7 Yrs  \n",
       "5             3-8 Yrs  \n",
       "6             2-7 Yrs  \n",
       "7             4-9 Yrs  \n",
       "8             3-8 Yrs  \n",
       "9             3-8 Yrs  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function\n",
    "def q_3(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\") # calling driver\n",
    "    driver.get(url) # loading url\n",
    "    search_modify = driver.find_element_by_xpath(\"//span[@class = 'quick-search-bar__view__modify-link']\")\n",
    "    search_modify.click()\n",
    "    search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    search_job.send_keys('Data Scientist')\n",
    "    search_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "    search_location.clear()\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'btn-primary']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "    filter_loc = driver.find_element_by_xpath(\"//span[@title= 'Delhi / NCR']\")\n",
    "    filter_loc.click()\n",
    "    time.sleep(3)\n",
    "    sal_range = driver.find_element_by_xpath(\"//span[@title= '3-6 Lakhs']\")\n",
    "    sal_range.click()\n",
    "    time.sleep(3)\n",
    "    # Scraping required data and making list of each required feature\n",
    "    post_name = []\n",
    "    company_name=[]\n",
    "    experience_required=[]\n",
    "    p_name = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    job_loc = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "    com_name = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    exp = driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "    for i in p_name[0:10]:\n",
    "        post_name.append(i.text)\n",
    "\n",
    "    for i in com_name[0:10]:\n",
    "        company_name.append(i.text)\n",
    "    \n",
    "    for i in job_loc[0:30]:\n",
    "        experience_required.append(i.text)\n",
    "        \n",
    "    driver.close()  \n",
    "    df = pd.DataFrame({})# creating data frame\n",
    "    df['job_title'] = post_name[0:10]\n",
    "    df['job_location'] = experience_required[2::3][0:10]\n",
    "    df['company_name']= company_name[0:10]\n",
    "    df['experience_required'] = experience_required[0::3][0:10]\n",
    "    df.to_csv('A_2_Q3.csv') # Saving csv file\n",
    "    return(df) # function output\n",
    "\n",
    "q_3('https://www.naukri.com/jobs-in-india')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown \n",
    "page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>company_name</th>\n",
       "      <th>days_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>BlackRock</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>BlackRock</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.3</td>\n",
       "      <td>Knoldus Inc</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.2</td>\n",
       "      <td>abc consultants</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.7</td>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.1</td>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.8</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.8</td>\n",
       "      <td>Healtheoz India</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Techlive</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating          company_name days_posted\n",
       "0    4.0             BlackRock          20\n",
       "1    4.0             BlackRock          20\n",
       "2    4.3           Knoldus Inc          24\n",
       "3    4.4                 Adobe           3\n",
       "4    4.2       abc consultants           2\n",
       "5    3.7       Priority Vendor           1\n",
       "6    3.1  Gauge Data Solutions           1\n",
       "7    3.8        Biz2Credit Inc          10\n",
       "8    4.8       Healtheoz India           1\n",
       "9    5.0              Techlive           7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q_4(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    click_signin = driver.find_element_by_xpath(\"//div[@class = 'locked-home-sign-in']\")\n",
    "    click_signin.click()\n",
    "    time.sleep(2)\n",
    "    enter_user_id = driver.find_element_by_id(\"userEmail\")\n",
    "    enter_user_id.send_keys('dearsun3291@yahoo.co.in')\n",
    "    enter_password = driver.find_element_by_id(\"userPassword\")\n",
    "    enter_password.send_keys('Bluesky*1923')\n",
    "    sign_in = driver.find_element_by_xpath(\"//button[@class = 'gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "    sign_in.click()\n",
    "    time.sleep(3)\n",
    "    enter_title = driver.find_element_by_xpath(\"//input[@id = 'sc.keyword']\")\n",
    "    time.sleep(3)\n",
    "    enter_title.send_keys(\"Data Scientist\")\n",
    "    time.sleep(3)\n",
    "    enter_location = driver.find_element_by_id('sc.location')\n",
    "    for i in range(0,20):\n",
    "        enter_location.send_keys(Keys.BACK_SPACE)\n",
    "        \n",
    "    \n",
    "    enter_location.send_keys(\"Noida\")\n",
    "    \n",
    "    search = driver.find_element_by_xpath(\"//button[@class = 'gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "    search.click()\n",
    "    time.sleep(5)\n",
    "    comp = []\n",
    "    company_name = driver.find_elements_by_xpath(\"//a[@class = ' css-l2wjgv e1n63ojh0 jobLink']/span\")\n",
    "    for i in company_name[0:10]:\n",
    "        comp.append(i.text)\n",
    "    days = []\n",
    "    days_posted = driver.find_elements_by_xpath(\"//div[@class = 'd-flex align-items-end pl-std css-mi55ob']\")\n",
    "    for i in days_posted[0:10]:\n",
    "        days.append(i.text)\n",
    "    \n",
    "    soup = bs(driver.page_source, 'lxml')\n",
    "    rate = [x.text for x in soup.find_all('span', class_= 'css-19pjha7 e1cjmv6j1')]\n",
    "    df = pd.DataFrame({})\n",
    "    df['rating']=rate[:10]\n",
    "    df['company_name'] = comp[:10]\n",
    "    df['days_posted']= days[:10]\n",
    "    df['days_posted'] = df['days_posted'].str.extract('(\\d+)')\n",
    "    driver.close()\n",
    "    df.to_csv('A_2_Q4.csv')\n",
    "    return(df)\n",
    "\n",
    "# calling function q_4 to scraping required data\n",
    "q_4('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company \n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>No. of salaries</th>\n",
       "      <th>Avg_Salary(in Rs.)</th>\n",
       "      <th>Max_Salary(in L Rs)</th>\n",
       "      <th>Min_Salary(in L Rs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 5,97,967</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 11,12,243</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 12,12,741</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>13</td>\n",
       "      <td>₹ 7,37,972</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12</td>\n",
       "      <td>₹ 7,15,984</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>10</td>\n",
       "      <td>₹ 13,41,900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9</td>\n",
       "      <td>₹ 7,90,812</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8</td>\n",
       "      <td>₹ 11,81,047</td>\n",
       "      <td>6.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 9,89,924</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 11,73,127</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name No. of salaries Avg_Salary(in Rs.)  \\\n",
       "0  Tata Consultancy Services              14         ₹ 5,97,967   \n",
       "1                  Accenture              14        ₹ 11,12,243   \n",
       "2                  Delhivery              14        ₹ 12,12,741   \n",
       "3                        IBM              13         ₹ 7,37,972   \n",
       "4         Ericsson-Worldwide              12         ₹ 7,15,984   \n",
       "5         UnitedHealth Group              10        ₹ 13,41,900   \n",
       "6         Valiance Solutions               9         ₹ 7,90,812   \n",
       "7                 Innovaccer               8        ₹ 11,81,047   \n",
       "8              ZS Associates               7         ₹ 9,89,924   \n",
       "9                EXL Service               7        ₹ 11,73,127   \n",
       "\n",
       "   Max_Salary(in L Rs)  Min_Salary(in L Rs)  \n",
       "0                 3.33                 0.01  \n",
       "1                 5.60                 0.02  \n",
       "2                 4.36                 0.11  \n",
       "3                 5.69                 0.02  \n",
       "4                 3.50                 0.01  \n",
       "5                 0.01                 0.01  \n",
       "6                 4.87                 0.01  \n",
       "7                 6.02                 0.01  \n",
       "8                 1.96                 0.01  \n",
       "9                 5.58                 0.01  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q_5(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    enter_title = driver.find_element_by_id(\"KeywordSearch\")\n",
    "    time.sleep(3)\n",
    "    enter_title.send_keys(\"Data Scientist\")\n",
    "    time.sleep(3)\n",
    "    enter_title = driver.find_element_by_id('LocationSearch')\n",
    "    enter_title.clear()\n",
    "    time.sleep(1)\n",
    "    enter_title.send_keys(\"Noida(India)\")\n",
    "    search = driver.find_element_by_xpath(\"//button[@class = 'gd-btn-mkt']\")\n",
    "    search.click()\n",
    "    time.sleep(3)\n",
    "    comp = []\n",
    "    company_name = driver.find_elements_by_xpath(\"//div[@class = 'row no-gutters mx-0 py align-items-center css-1u4lhyp']\")\n",
    "    for i in company_name[0:10]:\n",
    "        comp.append(i.text)\n",
    "    \n",
    "    driver.close()\n",
    "    df=pd.DataFrame({})\n",
    "    df['company_name']=comp[0:10]\n",
    "    df = pd.DataFrame(df['company_name'].str.split('\\n').tolist())\n",
    "    df.columns = ['Post','company_name','No. of salaries','x4','Avg_Salary(in Rs.)','x6','Max_Salary(in L Rs)','Min_Salary(in L Rs)']\n",
    "    df= df.drop(['Post','x4','x6'], axis = 1)\n",
    "    df['No. of salaries'] = df['No. of salaries'].str.extract('(\\d+)')\n",
    "    df['Min_Salary(in L Rs)'] = df['Min_Salary(in L Rs)'].str.extract('(\\d+)')\n",
    "    df['Min_Salary(in L Rs)'] = df['Min_Salary(in L Rs)'].astype(float)/100\n",
    "    df['Max_Salary(in L Rs)'] = df['Max_Salary(in L Rs)'].str.extract('(\\d+)')\n",
    "    df['Max_Salary(in L Rs)'] = df['Max_Salary(in L Rs)'].astype(float)/100\n",
    "    df.to_csv('A_2_Q5.csv')\n",
    "    return(df)\n",
    "\n",
    "q_5('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)  (B...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (49)  (S...</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size) ...</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)  (Black)</td>\n",
       "      <td>₹250</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)  ...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)  (R...</td>\n",
       "      <td>₹195</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹674</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)  ...</td>\n",
       "      <td>₹329</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)  (Black,...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              brand                                        description price  \\\n",
       "0        ROYAL SON   UV Protection Retro Square Sunglasses (88)  (B...  ₹599   \n",
       "1        ROYAL SON   UV Protection Retro Square Sunglasses (49)  (S...  ₹664   \n",
       "2         Fastrack   UV Protection Wayfarer Sunglasses (Free Size) ...  ₹758   \n",
       "3           PIRASO      UV Protection Aviator Sunglasses (54)  (Black)  ₹250   \n",
       "4           PIRASO   UV Protection Aviator Sunglasses (Free Size)  ...  ₹349   \n",
       "..              ...                                                ...   ...   \n",
       "95  ROZZETTA CRAFT   UV Protection, Gradient Rectangular Sunglasses...  ₹404   \n",
       "96    Singco India   UV Protection Round Sunglasses (Free Size)  (R...  ₹195   \n",
       "97        Fastrack   Gradient, UV Protection Wayfarer Sunglasses (F...  ₹674   \n",
       "98    Singco India   UV Protection Aviator Sunglasses (Free Size)  ...  ₹329   \n",
       "99          GANSTA   UV Protection Aviator Sunglasses (57)  (Black,...  ₹284   \n",
       "\n",
       "   discount  \n",
       "0   70% off  \n",
       "1   66% off  \n",
       "2   15% off  \n",
       "3   84% off  \n",
       "4   78% off  \n",
       "..      ...  \n",
       "95  79% off  \n",
       "96  80% off  \n",
       "97  15% off  \n",
       "98  72% off  \n",
       "99  85% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q_6 (url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    cross_btn = driver.find_element_by_xpath(\"//div[@class = '_2QfC02']/button\")\n",
    "    cross_btn.click()\n",
    "    search = driver.find_element_by_xpath(\"//div[@class = '_3OO5Xc']/input\")\n",
    "    search.clear()\n",
    "    search.send_keys('sunglasses')\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scraping url of all tiles\n",
    "    url_list = []\n",
    "    for j in range(0,3):\n",
    "        tile = driver.find_elements_by_xpath(\"//a[@class= '_2UzuFa']\")\n",
    "        for i in tile:\n",
    "            url_list.append(i.get_attribute('href'))\n",
    "            next_btn = driver.find_element_by_xpath(\"//a[@class = '_1LKTO3']/span\")\n",
    "            if next_btn.text == 'Next':\n",
    "                next_btn.click()\n",
    "    # Scraping data from all identified tiles\n",
    "    brand_name = []\n",
    "    product_description = []\n",
    "    price = []\n",
    "    discount = []\n",
    "    for i in url_list[0:100]:\n",
    "        driver.get(i)\n",
    "        time.sleep(1)\n",
    "        brand = driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_name.append(brand.text)\n",
    "        des = driver.find_element_by_xpath(\"//span[@class='B_NuCI']\")\n",
    "        product_description.append(des.text)\n",
    "        pri = driver.find_element_by_xpath(\"//div[@class = '_30jeq3 _16Jk6d']\")\n",
    "        price.append(pri.text)\n",
    "        dis = driver.find_element_by_xpath(\"//div[@class = '_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount.append(dis.text)\n",
    "    \n",
    "    driver.close()\n",
    "    #creating data frame\n",
    "    df = pd.DataFrame({})\n",
    "    df['brand']= brand_name[0:100]\n",
    "    df['description']= product_description[0:100]\n",
    "    df['price']= price[0:100]\n",
    "    df['discount']= discount[0:100]\n",
    "    df.to_csv('A_2_Q6.csv')\n",
    "    return(df)\n",
    "\n",
    "q_6('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️Its awesome mobile phone in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*Doesn't seem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      review_summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5   Worth every penny   \n",
       "3       5       Great product   \n",
       "4       5  Highly recommended   \n",
       "..    ...                 ...   \n",
       "95      5    Perfect product!   \n",
       "96      5    Perfect product!   \n",
       "97      5           Fabulous!   \n",
       "98      5           Wonderful   \n",
       "99      5   Worth every penny   \n",
       "\n",
       "                                               review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "..                                                ...  \n",
       "95  It’s a must buy who is looking for an upgrade ...  \n",
       "96  Value for money❤️❤️Its awesome mobile phone in...  \n",
       "97  This is my first iOS phone. I am very happy wi...  \n",
       "98  *Review after 10 months of usage*Doesn't seem ...  \n",
       "99  Best budget Iphone till date ❤️ go for it guys...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q_7(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    review = driver.find_element_by_xpath(\"//div[@class = '_3UAT2v _16PBlm']/span\")\n",
    "    review.click()\n",
    "    time.sleep(1)\n",
    "    rating = []\n",
    "    review_summary = []\n",
    "    review_full = []\n",
    "    for i in range(0,10):\n",
    "        soup = bs(driver.page_source, 'lxml')\n",
    "        rate = [x.text for x in soup.find_all('div', class_ = '_3LWZlK _1BLPMq')]\n",
    "        short_des = [x.text for x in soup.find_all('p', class_ = '_2-N8zT')]\n",
    "        review = [x.text for x in soup.find_all('div',class_='t-ZTKy')]\n",
    "        rating= rating+rate\n",
    "        review_summary= review_summary+ short_des\n",
    "        review_full= review_full + review\n",
    "        next_btn = driver.find_element_by_xpath(\"//a[@class = '_1LKTO3']/span\")\n",
    "        if next_btn.text =='Next':\n",
    "            next_btn.click()\n",
    "        time.sleep(3)\n",
    "    driver.close()\n",
    "    df = pd.DataFrame({})\n",
    "    df['rating']= rating\n",
    "    df['review_summary']=review_summary\n",
    "    df['review']= review_full\n",
    "    df.to_csv('A_2_Q7.csv')\n",
    "    return(df)\n",
    "\n",
    "q_7('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes%02earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men  (Black)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men  (Black)</td>\n",
       "      <td>₹396</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Sneakers For Men  (Red)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹211</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>White Sneakers Sneakers For Men  (White)</td>\n",
       "      <td>₹323</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Echor</td>\n",
       "      <td>shoes for boys Sneakers For Men  (Multicolor)</td>\n",
       "      <td>₹570</td>\n",
       "      <td>42% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand                                        description price  \\\n",
       "0         Chevit   Perfect & Affordable Combo Pack of 02 Pairs Sn...  ₹499   \n",
       "1   Robbie jones   Casual Sneakers Shoes For Men Sneakers For Men...  ₹399   \n",
       "2         Chevit   Combo Pack of 4 Casual Sneakers With Sneakers ...  ₹474   \n",
       "3         ORICUM   Combo pack of 2 casual sneaker shoes for men S...  ₹398   \n",
       "4           aadi                           Sneakers For Men  (Black)  ₹298   \n",
       "..            ...                                                ...   ...   \n",
       "95     ROCKFIELD                           Sneakers For Men  (Black)  ₹396   \n",
       "96      HOTSTYLE                             Sneakers For Men  (Red)  ₹199   \n",
       "97        Chevit   171 Smart Tan Lace-Ups Casuals for Men Sneaker...  ₹211   \n",
       "98      Magnolia            White Sneakers Sneakers For Men  (White)  ₹323   \n",
       "99         Echor       shoes for boys Sneakers For Men  (Multicolor)  ₹570   \n",
       "\n",
       "   discount  \n",
       "0   72% off  \n",
       "1   60% off  \n",
       "2   76% off  \n",
       "3   60% off  \n",
       "4   70% off  \n",
       "..      ...  \n",
       "95  60% off  \n",
       "96  60% off  \n",
       "97  57% off  \n",
       "98  67% off  \n",
       "99  42% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q_8(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    cross_btn = driver.find_element_by_xpath(\"//div[@class = '_2QfC02']/button\")\n",
    "    cross_btn.click()\n",
    "    search = driver.find_element_by_xpath(\"//div[@class = '_3OO5Xc']/input\")\n",
    "    search.clear()\n",
    "    search.send_keys('sneakers')\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    time.sleep(3)\n",
    "      # Scraping url of all tiles\n",
    "    url_list = []\n",
    "    for j in range(0,3):\n",
    "        tile = driver.find_elements_by_xpath(\"//a[@class= '_2UzuFa']\")\n",
    "        for i in tile:\n",
    "            url_list.append(i.get_attribute('href'))\n",
    "            next_btn = driver.find_element_by_xpath(\"//a[@class = '_1LKTO3']/span\")\n",
    "            if next_btn.text == 'Next':\n",
    "                next_btn.click()\n",
    "                \n",
    "    \n",
    "        # Scraping data from all identified tiles\n",
    "    brand_name = []\n",
    "    product_description = []\n",
    "    price = []\n",
    "    discount = []\n",
    "    for i in url_list[0:100]:\n",
    "        driver.get(i)\n",
    "        time.sleep(1)\n",
    "        brand = driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_name.append(brand.text)\n",
    "        des = driver.find_element_by_xpath(\"//span[@class='B_NuCI']\")\n",
    "        product_description.append(des.text)\n",
    "        pri = driver.find_element_by_xpath(\"//div[@class = '_30jeq3 _16Jk6d']\")\n",
    "        price.append(pri.text)\n",
    "        dis = driver.find_element_by_xpath(\"//div[@class = '_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount.append(dis.text)\n",
    "    \n",
    "    driver.close()\n",
    "    #creating data frame\n",
    "    df = pd.DataFrame({})\n",
    "    df['brand']= brand_name[0:100]\n",
    "    df['description']= product_description[0:100]\n",
    "    df['price']= price[0:100]\n",
    "    df['discount']= discount[0:100]\n",
    "    df.to_csv('A_2_Q8.csv')\n",
    "    return(df)\n",
    "      \n",
    "\n",
    "q_8('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>short_des</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Black Leather Loafers</td>\n",
       "      <td>Rs. 7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black AIR ZOOM VOMERO 15 Running Shoes</td>\n",
       "      <td>Rs. 10121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Black Mercedes Drift Cat 8 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black KD13 EP Mid-Top Basketball Shoes</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Black AIR ZOOM PEGASUS 37 FLYEASE Runnin...</td>\n",
       "      <td>Rs. 6996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Black AIR MAX VIVA Sneakers</td>\n",
       "      <td>Rs. 9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Florsheim</td>\n",
       "      <td>Men Black Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Black Solid Sandals</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Black SPEED Orbiter Running Shoes</td>\n",
       "      <td>Rs. 7149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Black TriBase Reign 2 Woven Design Train...</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              brand                                          short_des  \\\n",
       "0              ALDO                          Men Black Leather Loafers   \n",
       "1              Nike         Men Black AIR ZOOM VOMERO 15 Running Shoes   \n",
       "2   PUMA Motorsport    Unisex Black Mercedes Drift Cat 8 Running Shoes   \n",
       "3              Nike         Men Black KD13 EP Mid-Top Basketball Shoes   \n",
       "4              Nike  Women Black AIR ZOOM PEGASUS 37 FLYEASE Runnin...   \n",
       "..              ...                                                ...   \n",
       "95             Nike                  Women Black AIR MAX VIVA Sneakers   \n",
       "96        Florsheim              Men Black Solid Leather Formal Derbys   \n",
       "97        Cole Haan                          Women Black Solid Sandals   \n",
       "98             Puma            Women Black SPEED Orbiter Running Shoes   \n",
       "99     UNDER ARMOUR  Women Black TriBase Reign 2 Woven Design Train...   \n",
       "\n",
       "        price  \n",
       "0    Rs. 7799  \n",
       "1   Rs. 10121  \n",
       "2    Rs. 7999  \n",
       "3   Rs. 12995  \n",
       "4    Rs. 6996  \n",
       "..        ...  \n",
       "95   Rs. 9996  \n",
       "96   Rs. 6995  \n",
       "97   Rs. 7499  \n",
       "98   Rs. 7149  \n",
       "99  Rs. 11999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "def q_9(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\clear\\Desktop\\webdriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    y = driver.find_element_by_xpath(\"//li[@class = 'colour-listItem']/label[1]\")\n",
    "    y.click()\n",
    "    time.sleep(2)\n",
    "    x = driver.find_element_by_xpath(\"//ul[@class = 'price-list']/li[2]/label\")\n",
    "    x.click()\n",
    "    time.sleep(2)\n",
    "    links = []\n",
    "    for j in range(1,4):\n",
    "        try:\n",
    "            link = driver.find_elements_by_xpath(\"//a[@target = '_blank']\")\n",
    "            for i in link:\n",
    "                links.append(i.get_attribute('href'))\n",
    "        except StaleElementReferenceException:\n",
    "            links.append(np.NaN)\n",
    "    \n",
    "        next_btn = driver.find_element_by_xpath(\"//a[@rel = 'next']\")\n",
    "        if next_btn.text == 'Next':\n",
    "            next_btn.click()\n",
    "\n",
    "            \n",
    "    brand =[]\n",
    "    short_des =[]\n",
    "    price = []\n",
    "    for i in links[0:100]:\n",
    "        driver.get(i)\n",
    "        brands = driver.find_elements_by_xpath(\"//h1[@class = 'pdp-title']\")\n",
    "        des = driver.find_elements_by_xpath(\"//h1[@class = 'pdp-name']\")\n",
    "        pri = driver.find_elements_by_xpath(\"//span[@class = 'pdp-price']/strong\")\n",
    "        for j in brands:\n",
    "            brand.append(j.text)\n",
    "        \n",
    "        for j in des:\n",
    "            short_des.append(j.text)\n",
    "    \n",
    "        for j in pri:\n",
    "            price.append(j.text)\n",
    "        \n",
    "\n",
    "    driver.close()\n",
    "    df = pd.DataFrame({})\n",
    "    df['brand']= brand\n",
    "    df['short_des']= short_des\n",
    "    df['price']= price\n",
    "    df.to_csv('A_2_Q9.csv')\n",
    "    return(df)\n",
    "\n",
    "q_9('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
